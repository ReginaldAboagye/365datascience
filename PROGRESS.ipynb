{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReginaldAboagye/365datascience/blob/master/PROGRESS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XdONkD2QSlgV",
        "outputId": "d3dad8f0-eaef-4bf7-d855-d60f1fe36430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (245, 1), y shape: (245,)\n",
            "Initial X: [[5.69925642]\n",
            " [5.61924076]\n",
            " [5.59720039]\n",
            " [5.5917654 ]\n",
            " [5.71978855]]\n",
            "Initial y: [0.11027197 0.10549117 0.10158944 0.10152503 0.10482477]\n",
            "Posterior mean estimates\n",
            "mu: 0.0\n",
            "phi: 0.9000000000000002\n",
            "sigma_eta: 0.10000000000000002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "float() argument must be a string or a real number, not 'function'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fbabdf4462b1>\u001b[0m in \u001b[0;36m<cell line: 240>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;31m# Instantiate and fit the hybrid model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0mhybrid_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybridModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-fbabdf4462b1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, log_returns)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0msigma_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         sample_weight = np.asarray(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'function'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "import yfinance as yf\n",
        "from cvxopt import matrix, solvers\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "ticker = \"AAPL\"\n",
        "data = yf.download(ticker, start=\"2008-05-01\", end=\"2009-05-20\")\n",
        "data['Returns'] = data['Adj Close']\n",
        "data.dropna(inplace=True)\n",
        "data['Volatility'] = data['Returns'].rolling(window=21).std()\n",
        "data.dropna(inplace=True)\n",
        "X = data[['Returns']].values\n",
        "y = data['Volatility'].values\n",
        "\n",
        "# Debug: Print initial data stats\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "print(f\"Initial X: {X[:5]}\")\n",
        "print(f\"Initial y: {y[:5]}\")\n",
        "\n",
        "# Define a function to calculate the Gaussian kernel between two points x and y with a given sigma\n",
        "def gaussian_kernel(x, y, sigma):\n",
        "    distance_squared = np.linalg.norm(x - y) ** 2\n",
        "    return np.exp(-distance_squared / (2 * sigma ** 2))\n",
        "\n",
        "\"\"\"\n",
        "# Define a Support Vector Regressor (SVR)\n",
        "class SVM:\n",
        "    def __init__(self, C=1.0):\n",
        "        self.C = C  # Regularization parameter\n",
        "        self.alpha = None  # Lagrange multipliers\n",
        "        self.b = 0  # Bias term\n",
        "        self.support_vectors = None  # Support vectors\n",
        "        self.y_sv = None  # Labels of support vectors\n",
        "\n",
        "    def fit(self, X, y, sigma_func):\n",
        "        n_samples, n_features = X.shape\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i, j] = gaussian_kernel(X[i], X[j], sigma_func(i, j))\n",
        "\n",
        "        P = matrix(np.outer(y, y) * K)\n",
        "        q = matrix(-np.ones(n_samples))\n",
        "        G = matrix(np.vstack((-np.eye(n_samples), np.eye(n_samples))))\n",
        "        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C)))\n",
        "        A = matrix(y.reshape(1, -1).astype(float))\n",
        "        b = matrix(np.zeros(1))\n",
        "\n",
        "        sol = solvers.qp(P, q, G, h, A, b)\n",
        "        alpha = np.ravel(sol['x'])\n",
        "\n",
        "        sv = alpha > 1e-5\n",
        "        self.alpha = alpha[sv]\n",
        "        self.support_vectors = X[sv]\n",
        "        self.y_sv = y[sv]\n",
        "        self.b = np.mean(self.y_sv - np.sum(self.alpha * self.y_sv * K[sv][:, sv], axis=1))\n",
        "\n",
        "    def predict(self, X, sigma_func):\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            prediction = sum(self.alpha[i] * self.y_sv[i] * gaussian_kernel(x, self.support_vectors[i], sigma_func(i, i))\n",
        "                             for i in range(len(self.alpha))) + self.b\n",
        "            y_pred.append(np.sign(prediction))\n",
        "        return np.array(y_pred)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Define an Extended Kalman Filter (EKF) class\n",
        "class EKF:\n",
        "    def __init__(self, F, H, Q, R):\n",
        "        self.F = F\n",
        "        self.H = H\n",
        "        self.Q = Q\n",
        "        self.R = R\n",
        "\n",
        "    def predict(self, x, P):\n",
        "        x_pred = self.F @ x\n",
        "        P_pred = self.F @ P @ self.F.T + self.Q\n",
        "        return x_pred, P_pred\n",
        "\n",
        "    def update(self, x_pred, P_pred, y):\n",
        "        y_pred = self.H @ x_pred\n",
        "        S = self.H @ P_pred @ self.H.T + self.R\n",
        "        K = P_pred @ self.H.T @ np.linalg.inv(S)\n",
        "        x_upd = x_pred + K @ (y - y_pred)\n",
        "        P_upd = P_pred - K @ self.H @ P_pred\n",
        "        return x_upd, P_upd\n",
        "\n",
        "    def run(self, y, x0, P0):\n",
        "        n = len(y)\n",
        "        x_est = np.zeros((n, len(x0)))\n",
        "        x_est[0] = x0\n",
        "        P = P0\n",
        "        for t in range(1, n):\n",
        "            x_pred, P_pred = self.predict(x_est[t-1], P)\n",
        "            x_est[t], P = self.update(x_pred, P_pred, y[t])\n",
        "        return x_est\n",
        "\n",
        "# Define a Bayesian Stochastic Volatility EKF-HMC class\n",
        "class BayesianStochasticVolatilityEKF_HMC:\n",
        "    def __init__(self, F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.ekf = EKF(F, H, Q, R)\n",
        "        self.mu_prior = mu_prior\n",
        "        self.phi_prior = phi_prior\n",
        "        self.sigma_eta_prior = sigma_eta_prior\n",
        "        self.n_iter = n_iter\n",
        "        self.epsilon = epsilon\n",
        "        self.L = L\n",
        "\n",
        "    def potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = sigma_eta if np.isscalar(sigma_eta) else sigma_eta.item()\n",
        "        if sigma_eta <= 0:\n",
        "            return np.inf\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        likelihood = -0.5 * np.sum((y - x_est.flatten()) ** 2)\n",
        "        prior = -0.5 * (mu - self.mu_prior[0]) ** 2 / self.mu_prior[1] ** 2 \\\n",
        "                -0.5 * (phi - self.phi_prior[0]) ** 2 / self.phi_prior[1] ** 2 \\\n",
        "                -0.5 * (sigma_eta - self.sigma_eta_prior[0]) ** 2 / self.sigma_eta_prior[1] ** 2\n",
        "        return -(likelihood + prior)\n",
        "\n",
        "    def gradient_potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = np.atleast_1d(sigma_eta)[0]\n",
        "\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        grad_mu = 0\n",
        "        grad_phi = 0\n",
        "        grad_sigma_eta = 0\n",
        "        for t in range(1, len(y)):\n",
        "            grad_mu += (y[t] - x_est[t]) / np.exp(x_est[t])\n",
        "            grad_phi += (y[t] - x_est[t]) * (x_est[t-1] - mu) / np.exp(x_est[t])\n",
        "            grad_sigma_eta += (y[t] - mu - phi * y[t-1]) ** 2 / (2 * sigma_eta ** 3)\n",
        "\n",
        "        grad_mu -= (mu - self.mu_prior[0]) / self.mu_prior[1] ** 2\n",
        "        grad_phi -= (phi - self.phi_prior[0]) / self.phi_prior[1] ** 2\n",
        "        grad_sigma_eta -= (sigma_eta - self.sigma_eta_prior[0]) / self.sigma_eta_prior[1] ** 2\n",
        "\n",
        "        return np.array([grad_mu.item(), grad_phi.item(), grad_sigma_eta.item()])\n",
        "\n",
        "    def leapfrog(self, params, momentum, grad, epsilon):\n",
        "        momentum_half_step = momentum - 0.5 * epsilon * grad\n",
        "        params_full_step = params + epsilon * momentum_half_step\n",
        "        grad_new = self.gradient_potential_energy(params_full_step, log_returns)\n",
        "        momentum_full_step = momentum_half_step - 0.5 * epsilon * grad_new\n",
        "        return params_full_step, momentum_full_step, grad_new\n",
        "\n",
        "    def hmc_step(self, params, y):\n",
        "        momentum = np.random.normal(size=params.shape)\n",
        "        current_params = params.copy()\n",
        "        current_momentum = momentum.copy()\n",
        "        current_grad = self.gradient_potential_energy(params, y)\n",
        "        proposed_params = params.copy()\n",
        "        proposed_momentum = momentum.copy()\n",
        "\n",
        "        for _ in range(self.L):\n",
        "            proposed_params, proposed_momentum, current_grad = self.leapfrog(proposed_params, proposed_momentum, current_grad, self.epsilon)\n",
        "\n",
        "        current_potential = self.potential_energy(current_params, y)\n",
        "        current_kinetic = 0.5 * np.sum(current_momentum ** 2)\n",
        "        proposed_potential = self.potential_energy(proposed_params, y)\n",
        "        proposed_kinetic = 0.5 * np.sum(proposed_momentum ** 2)\n",
        "\n",
        "        if np.random.uniform() < np.exp(current_potential - proposed_potential + current_kinetic - proposed_kinetic):\n",
        "            return proposed_params\n",
        "        else:\n",
        "            return current_params\n",
        "\n",
        "    def fit(self, y):\n",
        "        params = np.array([self.mu_prior[0], self.phi_prior[0], self.sigma_eta_prior[0]])\n",
        "        samples = np.zeros((self.n_iter, 3))\n",
        "        for i in range(self.n_iter):\n",
        "            params = self.hmc_step(params, y)\n",
        "            samples[i] = params\n",
        "        return samples\n",
        "\n",
        "log_returns = np.diff(np.log(data['Returns']))\n",
        "\n",
        "F = np.array([[0.9]])\n",
        "H = np.array([[1]])\n",
        "Q = np.array([[0.01]])\n",
        "R = np.array([[1]])\n",
        "\n",
        "hmc_ekf_model = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior=(0, 1), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10)\n",
        "samples = hmc_ekf_model.fit(log_returns)\n",
        "\n",
        "# Debug: Print samples summary\n",
        "print(\"Posterior mean estimates\")\n",
        "print(\"mu:\", np.mean(samples[:, 0]))\n",
        "print(\"phi:\", np.mean(samples[:, 1]))\n",
        "print(\"sigma_eta:\", np.mean(samples[:, 2]))\n",
        "\n",
        "class HybridModel:\n",
        "    def __init__(self, C=1.0, mu_prior=(0.0, 1.0), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.svm = SVR(kernel=\"rbf\")\n",
        "        F = np.array([[phi_prior[0]]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta_prior[0] ** 2]])\n",
        "        R = np.array([[1]])\n",
        "        self.bsv = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter, epsilon, L)\n",
        "\n",
        "    def fit(self, X, y, log_returns):\n",
        "        samples = self.bsv.fit(log_returns)\n",
        "        h = np.mean(samples, axis=0)\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))\n",
        "        self.svm.fit(X, y, sigma_func)\n",
        "\n",
        "    def predict(self, X):\n",
        "        samples = self.bsv.fit(np.zeros(len(X)))\n",
        "        h = np.mean(samples, axis=0)\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))\n",
        "        return self.svm.predict(X, sigma_func)\n",
        "\n",
        "# Instantiate and fit the hybrid model\n",
        "hybrid_model = HybridModel()\n",
        "hybrid_model.fit(X, y, log_returns)\n",
        "\n",
        "# Predictions\n",
        "data1 = yf.download(ticker, start=\"2024-05-01\", end=\"2024-06-30\")\n",
        "data1['Returns'] = data1['Adj Close']\n",
        "data1.dropna(inplace=True)\n",
        "data1['Volatility'] = data1['Returns'].rolling(window=21).std()\n",
        "data1.dropna(inplace=True)\n",
        "X_test = data1[['Returns']].values\n",
        "y_test = data1['Volatility'].values\n",
        "\n",
        "hybrid_predictions = hybrid_model.predict(X_test)\n",
        "\n",
        "# Debug: Check for NaN in predictions\n",
        "print(\"Hybrid Predictions: \", hybrid_predictions)\n",
        "print(\"NaN in predictions: \", np.isnan(hybrid_predictions).any())\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "    conf_matrix = confusion_matrix(y_test, hybrid_predictions)\n",
        "    class_report = classification_report(y_test, hybrid_predictions)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"Classification Report:\\n\", class_report)\n",
        "-except ValueError as e:\n",
        "    print(\"Error in metrics calculation:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "import yfinance as yf\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "ticker = \"AAPL\"\n",
        "data = yf.download(ticker, start=\"2000-01-01\", end=\"2023-12-31\")\n",
        "data['Returns'] = data['Adj Close']\n",
        "data.dropna(inplace=True)\n",
        "data['Volatility'] = data['Returns'].rolling(window=21).std()\n",
        "data.dropna(inplace=True)\n",
        "X = data[['Returns']].values\n",
        "y = data['Volatility'].values\n",
        "\n",
        "# Debug: Print initial data stats\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "print(f\"Initial X: {X[:5]}\")\n",
        "print(f\"Initial y: {y[:5]}\")\n",
        "\n",
        "# Define an Extended Kalman Filter (EKF) class\n",
        "class EKF:\n",
        "    def __init__(self, F, H, Q, R):\n",
        "        self.F = F\n",
        "        self.H = H\n",
        "        self.Q = Q\n",
        "        self.R = R\n",
        "\n",
        "    def predict(self, x, P):\n",
        "        x_pred = self.F @ x\n",
        "        P_pred = self.F @ P @ self.F.T + self.Q\n",
        "        return x_pred, P_pred\n",
        "\n",
        "    def update(self, x_pred, P_pred, y):\n",
        "        y_pred = self.H @ x_pred\n",
        "        S = self.H @ P_pred @ self.H.T + self.R\n",
        "        K = P_pred @ self.H.T @ np.linalg.inv(S)\n",
        "        x_upd = x_pred + K @ (y - y_pred)\n",
        "        P_upd = P_pred - K @ self.H @ P_pred\n",
        "        return x_upd, P_upd\n",
        "\n",
        "    def run(self, y, x0, P0):\n",
        "        n = len(y)\n",
        "        x_est = np.zeros((n, len(x0)))\n",
        "        x_est[0] = x0\n",
        "        P = P0\n",
        "        for t in range(1, n):\n",
        "            x_pred, P_pred = self.predict(x_est[t-1], P)\n",
        "            x_est[t], P = self.update(x_pred, P_pred, y[t])\n",
        "        return x_est\n",
        "\n",
        "# Define a Bayesian Stochastic Volatility EKF-HMC class\n",
        "class BayesianStochasticVolatilityEKF_HMC:\n",
        "    def __init__(self, F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.ekf = EKF(F, H, Q, R)\n",
        "        self.mu_prior = mu_prior\n",
        "        self.phi_prior = phi_prior\n",
        "        self.sigma_eta_prior = sigma_eta_prior\n",
        "        self.n_iter = n_iter\n",
        "        self.epsilon = epsilon\n",
        "        self.L = L\n",
        "\n",
        "    def potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = sigma_eta if np.isscalar(sigma_eta) else sigma_eta.item()\n",
        "        if sigma_eta <= 0:\n",
        "            return np.inf\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        likelihood = -0.5 * np.sum((y - x_est.flatten()) ** 2)\n",
        "        prior = -0.5 * (mu - self.mu_prior[0]) ** 2 / self.mu_prior[1] ** 2 \\\n",
        "                -0.5 * (phi - self.phi_prior[0]) ** 2 / self.phi_prior[1] ** 2 \\\n",
        "                -0.5 * (sigma_eta - self.sigma_eta_prior[0]) ** 2 / self.sigma_eta_prior[1] ** 2\n",
        "        return -(likelihood + prior)\n",
        "\n",
        "    def gradient_potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = np.atleast_1d(sigma_eta)[0]\n",
        "\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        grad_mu = 0\n",
        "        grad_phi = 0\n",
        "        grad_sigma_eta = 0\n",
        "        for t in range(1, len(y)):\n",
        "            grad_mu += (y[t] - x_est[t]) / np.exp(x_est[t])\n",
        "            grad_phi += (y[t] - x_est[t]) * (x_est[t-1] - mu) / np.exp(x_est[t])\n",
        "            grad_sigma_eta += (y[t] - mu - phi * y[t-1]) ** 2 / (2 * sigma_eta ** 3)\n",
        "\n",
        "        grad_mu -= (mu - self.mu_prior[0]) / self.mu_prior[1] ** 2\n",
        "        grad_phi -= (phi - self.phi_prior[0]) / self.phi_prior[1] ** 2\n",
        "        grad_sigma_eta -= (sigma_eta - self.sigma_eta_prior[0]) / self.sigma_eta_prior[1] ** 2\n",
        "\n",
        "        return np.array([grad_mu.item(), grad_phi.item(), grad_sigma_eta.item()])\n",
        "\n",
        "    def leapfrog(self, params, momentum, grad, epsilon):\n",
        "        momentum_half_step = momentum - 0.5 * epsilon * grad\n",
        "        params_full_step = params + epsilon * momentum_half_step\n",
        "        grad_new = self.gradient_potential_energy(params_full_step, log_returns)\n",
        "        momentum_full_step = momentum_half_step - 0.5 * epsilon * grad_new\n",
        "        return params_full_step, momentum_full_step, grad_new\n",
        "\n",
        "    def hmc_step(self, params, y):\n",
        "        momentum = np.random.normal(size=params.shape)\n",
        "        current_params = params.copy()\n",
        "        current_momentum = momentum.copy()\n",
        "        current_grad = self.gradient_potential_energy(params, y)\n",
        "        proposed_params = params.copy()\n",
        "        proposed_momentum = momentum.copy()\n",
        "\n",
        "        for _ in range(self.L):\n",
        "            proposed_params, proposed_momentum, current_grad = self.leapfrog(proposed_params, proposed_momentum, current_grad, self.epsilon)\n",
        "\n",
        "        current_potential = self.potential_energy(current_params, y)\n",
        "        current_kinetic = 0.5 * np.sum(current_momentum ** 2)\n",
        "        proposed_potential = self.potential_energy(proposed_params, y)\n",
        "        proposed_kinetic = 0.5 * np.sum(proposed_momentum ** 2)\n",
        "\n",
        "        if np.random.uniform() < np.exp(current_potential - proposed_potential + current_kinetic - proposed_kinetic):\n",
        "            return proposed_params\n",
        "        else:\n",
        "            return current_params\n",
        "\n",
        "    def fit(self, y):\n",
        "        params = np.array([self.mu_prior[0], self.phi_prior[0], self.sigma_eta_prior[0]])\n",
        "        samples = np.zeros((self.n_iter, 3))\n",
        "        for i in range(self.n_iter):\n",
        "            params = self.hmc_step(params, y)\n",
        "            samples[i] = params\n",
        "        return samples\n",
        "\n",
        "log_returns = np.diff(np.log(data['Returns']))\n",
        "\n",
        "F = np.array([[0.9]])\n",
        "H = np.array([[1]])\n",
        "Q = np.array([[0.01]])\n",
        "R = np.array([[1]])\n",
        "\n",
        "hmc_ekf_model = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior=(0, 1), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10)\n",
        "samples = hmc_ekf_model.fit(log_returns)\n",
        "\n",
        "# Debug: Print samples summary\n",
        "print(\"Posterior mean estimates\")\n",
        "print(\"mu:\", np.mean(samples[:, 0]))\n",
        "print(\"phi:\", np.mean(samples[:, 1]))\n",
        "print(\"sigma_eta:\", np.mean(samples[:, 2]))\n",
        "\n",
        "class HybridModel:\n",
        "    def __init__(self, C=1.0, mu_prior=(0.0, 1.0), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.svm = SVR(kernel=\"rbf\")\n",
        "        F = np.array([[phi_prior[0]]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta_prior[0] ** 2]])\n",
        "        R = np.array([[1]])\n",
        "        self.bsv = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter, epsilon, L)\n",
        "\n",
        "    def fit(self, X, y, log_returns):\n",
        "        samples = self.bsv.fit(log_returns)\n",
        "        h = np.mean(samples, axis=0)\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))\n",
        "        self.svm.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        samples = self.bsv.fit(np.zeros(len(X)))\n",
        "        h = np.mean(samples, axis=0)\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))\n",
        "        return self.svm.predict(X)\n",
        "\n",
        "# Instantiate and fit the hybrid model\n",
        "hybrid_model = HybridModel()\n",
        "hybrid_model.fit(X, y, log_returns)\n",
        "\n",
        "# Predictions\n",
        "data1 = yf.download(ticker, start=\"2024-01-01\", end=\"2024-06-30\")\n",
        "data1['Returns'] = data1['Adj Close']\n",
        "data1.dropna(inplace=True)\n",
        "data1['Volatility'] = data1['Returns'].rolling(window=21).std()\n",
        "data1.dropna(inplace=True)\n",
        "X_test = data1[['Returns']].values\n",
        "y_test = data1['Volatility'].values\n",
        "\n",
        "hybrid_predictions = hybrid_model.predict(X_test)\n",
        "\n",
        "# Debug: Check for NaN in predictions\n",
        "print(\"Hybrid Predictions: \", hybrid_predictions)\n",
        "print(\"NaN in predictions: \", np.isnan(hybrid_predictions).any())\n",
        "\n",
        "# Calculate regression metrics\n",
        "mse = mean_squared_error(y_test, hybrid_predictions)\n",
        "mae = mean_absolute_error(y_test, hybrid_predictions)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8xc1nZbrIjL",
        "outputId": "6d66f950-d256-4ae3-9439-bb7c3fc28564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (6017, 1), y shape: (6017,)\n",
            "Initial X: [[0.75675553]\n",
            " [0.74590403]\n",
            " [0.77987349]\n",
            " [0.81525826]\n",
            " [0.8610217 ]]\n",
            "Initial y: [0.05296062 0.05118237 0.05119596 0.05192094 0.05322455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "    conf_matrix = confusion_matrix(y_test, hybrid_predictions)\n",
        "    class_report = classification_report(y_test, hybrid_predictions)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"Classification Report:\\n\", class_report)\n",
        "except ValueError as e:\n",
        "    print(\"Error in metrics calculation:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSvdhOG3avCl",
        "outputId": "e7acb889-5c04-45f1-ddfc-c793c669a89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in metrics calculation: continuous is not supported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "import yfinance as yf\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "ticker = \"AAPL\"  # Ticker symbol for Apple Inc.\n",
        "data = yf.download(ticker, start=\"2008-05-01\", end=\"2009-05-20\")  # Download historical stock data\n",
        "\n",
        "if data.empty:  # Check if data is empty\n",
        "    raise ValueError(\"No data was downloaded. Please check the ticker symbol or the date range.\")  # Raise error if no data\n",
        "\n",
        "data['Returns'] = data['Adj Close'].pct_change()  # Calculate daily returns\n",
        "data.dropna(inplace=True)  # Remove missing values\n",
        "data['Volatility'] = data['Returns'].rolling(window=21).std()  # Calculate rolling volatility\n",
        "data.dropna(inplace=True)  # Remove missing values\n",
        "\n",
        "X = data[['Returns']].values  # Features (returns)\n",
        "y = data['Volatility'].values  # Target (volatility)\n",
        "\n",
        "# Debug: Print initial data stats\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "print(f\"Initial X: {X[:5]}\")\n",
        "print(f\"Initial y: {y[:5]}\")\n",
        "\n",
        "# Define a function to calculate the Gaussian kernel between two points x and y with a given sigma\n",
        "def gaussian_kernel(x, y, sigma):\n",
        "    distance_squared = np.linalg.norm(x - y) ** 2  # Calculate squared Euclidean distance\n",
        "    return np.exp(-distance_squared / (2 * sigma ** 2))  # Apply Gaussian function\n",
        "\n",
        "# Define an Extended Kalman Filter (EKF) class\n",
        "class EKF:\n",
        "    def __init__(self, F, H, Q, R):\n",
        "        self.F = F  # State transition matrix\n",
        "        self.H = H  # Observation matrix\n",
        "        self.Q = Q  # Process noise covariance\n",
        "        self.R = R  # Observation noise covariance\n",
        "\n",
        "    def predict(self, x, P):\n",
        "        x_pred = self.F @ x  # Predict the state\n",
        "        P_pred = self.F @ P @ self.F.T + self.Q  # Predict the error covariance\n",
        "        return x_pred, P_pred\n",
        "\n",
        "    def update(self, x_pred, P_pred, y):\n",
        "        y_pred = self.H @ x_pred  # Predict the observation\n",
        "        S = self.H @ P_pred @ self.H.T + self.R  # Innovation (residual) covariance\n",
        "        K = P_pred @ self.H.T @ np.linalg.inv(S)  # Kalman gain\n",
        "        x_upd = x_pred + K @ (y - y_pred)  # Update the state estimate\n",
        "        P_upd = P_pred - K @ self.H @ P_pred  # Update the error covariance\n",
        "        return x_upd, P_upd\n",
        "\n",
        "    def run(self, y, x0, P0):\n",
        "        n = len(y)  # Number of observations\n",
        "        x_est = np.zeros((n, len(x0)))  # Initialize state estimates\n",
        "        x_est[0] = x0  # Set initial state\n",
        "        P = P0  # Set initial error covariance\n",
        "        for t in range(1, n):\n",
        "            x_pred, P_pred = self.predict(x_est[t-1], P)  # Prediction step\n",
        "            x_est[t], P = self.update(x_pred, P_pred, y[t])  # Update step\n",
        "        return x_est\n",
        "\n",
        "# Define a Bayesian Stochastic Volatility EKF-HMC class\n",
        "class BayesianStochasticVolatilityEKF_HMC:\n",
        "    def __init__(self, F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.ekf = EKF(F, H, Q, R)  # Initialize EKF\n",
        "        self.mu_prior = mu_prior  # Prior for mu\n",
        "        self.phi_prior = phi_prior  # Prior for phi\n",
        "        self.sigma_eta_prior = sigma_eta_prior  # Prior for sigma_eta\n",
        "        self.n_iter = n_iter  # Number of HMC iterations\n",
        "        self.epsilon = epsilon  # Step size for HMC\n",
        "        self.L = L  # Number of leapfrog steps\n",
        "\n",
        "    def potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = sigma_eta if np.isscalar(sigma_eta) else sigma_eta.item()\n",
        "        if sigma_eta <= 0:\n",
        "            return np.inf\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        likelihood = -0.5 * np.sum((y - x_est.flatten()) ** 2)\n",
        "        prior = -0.5 * (mu - self.mu_prior[0]) ** 2 / self.mu_prior[1] ** 2 \\\n",
        "                -0.5 * (phi - self.phi_prior[0]) ** 2 / self.phi_prior[1] ** 2 \\\n",
        "                -0.5 * (sigma_eta - self.sigma_eta_prior[0]) ** 2 / self.sigma_eta_prior[1] ** 2\n",
        "        return -(likelihood + prior)\n",
        "\n",
        "    def gradient_potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = np.atleast_1d(sigma_eta)[0]\n",
        "\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta ** 2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta ** 2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        grad_mu = 0\n",
        "        grad_phi = 0\n",
        "        grad_sigma_eta = 0\n",
        "        for t in range(1, len(y)):\n",
        "            grad_mu += (y[t] - x_est[t]) / np.exp(x_est[t])\n",
        "            grad_phi += (y[t] - x_est[t]) * (x_est[t-1] - mu) / np.exp(x_est[t])\n",
        "            grad_sigma_eta += (y[t] - mu - phi * y[t-1]) ** 2 / (2 * sigma_eta ** 3)\n",
        "\n",
        "        grad_mu -= (mu - self.mu_prior[0]) / self.mu_prior[1] ** 2\n",
        "        grad_phi -= (phi - self.phi_prior[0]) / self.phi_prior[1] ** 2\n",
        "        grad_sigma_eta -= (sigma_eta - self.sigma_eta_prior[0]) / self.sigma_eta_prior[1] ** 2\n",
        "\n",
        "        return np.array([grad_mu.item(), grad_phi.item(), grad_sigma_eta.item()])\n",
        "\n",
        "    def leapfrog(self, params, momentum, grad, epsilon):\n",
        "        momentum_half_step = momentum - 0.5 * epsilon * grad\n",
        "        params_full_step = params + epsilon * momentum_half_step\n",
        "        grad_new = self.gradient_potential_energy(params_full_step, log_returns)\n",
        "        momentum_full_step = momentum_half_step - 0.5 * epsilon * grad_new\n",
        "        return params_full_step, momentum_full_step, grad_new\n",
        "\n",
        "    def hmc_step(self, params, y):\n",
        "        momentum = np.random.normal(size=params.shape)\n",
        "        current_params = params.copy()\n",
        "        current_momentum = momentum.copy()\n",
        "        current_grad = self.gradient_potential_energy(params, y)\n",
        "        proposed_params = params.copy()\n",
        "        proposed_momentum = momentum.copy()\n",
        "\n",
        "        for _ in range(self.L):\n",
        "            proposed_params, proposed_momentum, current_grad = self.leapfrog(proposed_params, proposed_momentum, current_grad, self.epsilon)\n",
        "\n",
        "        current_potential = self.potential_energy(current_params, y)\n",
        "        current_kinetic = 0.5 * np.sum(current_momentum ** 2)\n",
        "        proposed_potential = self.potential_energy(proposed_params, y)\n",
        "        proposed_kinetic = 0.5 * np.sum(proposed_momentum ** 2)\n",
        "\n",
        "        if np.random.uniform() < np.exp(current_potential - proposed_potential + current_kinetic - proposed_kinetic):\n",
        "            return proposed_params\n",
        "        else:\n",
        "            return current_params\n",
        "\n",
        "    def fit(self, y):\n",
        "        if len(y) == 0:\n",
        "            raise ValueError(\"Input data is empty. Cannot fit the model.\")\n",
        "\n",
        "        params = np.array([self.mu_prior[0], self.phi_prior[0], self.sigma_eta_prior[0]])\n",
        "        samples = np.zeros((self.n_iter, 3))\n",
        "        for i in range(self.n_iter):\n",
        "            params = self.hmc_step(params, y)\n",
        "            samples[i] = params\n",
        "        return samples\n",
        "\n",
        "log_returns = np.diff(np.log(data['Returns']))  # Calculate log returns\n",
        "\n",
        "F = np.array([[0.9]])  # State transition matrix\n",
        "H = np.array([[1]])  # Observation matrix\n",
        "Q = np.array([[0.01]])  # Process noise covariance\n",
        "R = np.array([[1]])  # Observation noise covariance\n",
        "\n",
        "# Fit Bayesian Stochastic Volatility EKF-HMC model\n",
        "hmc_ekf_model = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior=(0, 1), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10)\n",
        "samples = hmc_ekf_model.fit(log_returns)\n",
        "\n",
        "# Debug: Print samples summary\n",
        "print(\"Samples summary:\")\n",
        "print(samples)\n",
        "\n",
        "# Define a hybrid model that combines SVM with Bayesian Stochastic Volatility EKF-HMC\n",
        "class HybridModel:\n",
        "    def __init__(self):\n",
        "        self.svm = SVR(kernel='rbf')  # Initialize SVR with RBF kernel\n",
        "        F = np.array([[0.9]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[0.01]])\n",
        "        R = np.array([[1]])\n",
        "        self.bsv = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior=(0, 1), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10)\n",
        "\n",
        "    def fit(self, X, y, log_returns):\n",
        "        samples = self.bsv.fit(log_returns)  # Fit the Bayesian Stochastic Volatility EKF-HMC model\n",
        "        h = np.mean(samples, axis=0)  # Calculate mean of samples\n",
        "        sigma_weights = np.sqrt(np.exp(h[0] + h[1]))  # Define sigma weights\n",
        "        self.svm.fit(X, y, sample_weight=sigma_weights)  # Fit the SVR model with sigma weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        samples = self.bsv.fit(np.zeros(len(X)))  # Fit the Bayesian Stochastic Volatility EKF-HMC model\n",
        "        h = np.mean(samples, axis=0)  # Calculate mean of samples\n",
        "        sigma_weights = np.sqrt(np.exp(h[0] + h[1]))  # Define sigma weights\n",
        "        return self.svm.predict(X, sample_weight=sigma_weights)  # Predict using SVR model with sigma weights\n",
        "\n",
        "# Instantiate and fit the hybrid model\n",
        "hybrid_model = HybridModel()\n",
        "hybrid_model.fit(X, y, log_returns)\n",
        "\n",
        "# Predictions\n",
        "predictions = hybrid_model.predict(X)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "AqxyxlRHcKuq",
        "outputId": "4fb39303-09d3-4fe1-b287-00b7244820af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (244, 1), y shape: (244,)\n",
            "Initial X: [[-0.01403967]\n",
            " [-0.0039223 ]\n",
            " [-0.00097102]\n",
            " [ 0.02289494]\n",
            " [-0.02000714]]\n",
            "Initial y: [0.01862592 0.01864767 0.01809953 0.01864491 0.01853943]\n",
            "Samples summary:\n",
            "[[0.  0.9 0.1]\n",
            " [0.  0.9 0.1]\n",
            " [0.  0.9 0.1]\n",
            " ...\n",
            " [0.  0.9 0.1]\n",
            " [0.  0.9 0.1]\n",
            " [0.  0.9 0.1]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3ad1c25a0e68>\u001b[0m in \u001b[0;36m<cell line: 202>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;31m# Instantiate and fit the hybrid model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0mhybrid_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybridModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-3ad1c25a0e68>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, log_returns)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate mean of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0msigma_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Define sigma weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_weights\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Fit the SVR model with sigma weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m             )\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             raise ValueError(\n\u001b[1;32m    224\u001b[0m                 \u001b[0;34m\"sample_weight and X have incompatible shapes: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}