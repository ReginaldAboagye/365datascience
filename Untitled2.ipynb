{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReginaldAboagye/365datascience/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d81ESHsjvmxC",
        "outputId": "e7f60ffb-12e4-428c-eb2d-199c89f4acba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.  1.  1. -1.  1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def gaussian_kernel(x, y, sigma):\n",
        "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * sigma**2))\n",
        "\n",
        "class SVM:\n",
        "    def __init__(self, C=1.0):\n",
        "        self.C = C\n",
        "        self.alpha = None\n",
        "        self.b = 0\n",
        "        self.support_vectors = None\n",
        "        self.y_sv = None\n",
        "\n",
        "    def fit(self, X, y, sigma_func):\n",
        "        n_samples, n_features = X.shape\n",
        "        K = np.zeros((n_samples, n_samples))\n",
        "        for i in range(n_samples):\n",
        "            for j in range(n_samples):\n",
        "                K[i, j] = gaussian_kernel(X[i], X[j], sigma_func(i, j))\n",
        "\n",
        "        P = np.outer(y, y) * K\n",
        "        q = -np.ones(n_samples)\n",
        "        G = np.vstack((-np.eye(n_samples), np.eye(n_samples)))\n",
        "        h = np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C))\n",
        "        A = y.reshape(1, -1)\n",
        "        b = np.zeros(1)\n",
        "\n",
        "        alpha = self.solve_qp(P, q, G, h, A, b)\n",
        "        sv = alpha > 1e-5\n",
        "        self.alpha = alpha[sv]\n",
        "        self.support_vectors = X[sv]\n",
        "        self.y_sv = y[sv]\n",
        "        self.b = np.mean(self.y_sv - np.sum(self.alpha * self.y_sv * K[sv][:, sv], axis=1))\n",
        "\n",
        "    def predict(self, X, sigma_func):\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            prediction = sum(self.alpha[i] * self.y_sv[i] * gaussian_kernel(x, self.support_vectors[i], sigma_func(i, i))\n",
        "                             for i in range(len(self.alpha))) + self.b\n",
        "            y_pred.append(np.sign(prediction))\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def solve_qp(self, P, q, G, h, A, b):\n",
        "        # Placeholder for QP solver implementation\n",
        "        return np.random.rand(P.shape[0])  # Dummy implementation\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]])\n",
        "y = np.array([1, 1, 1, -1, -1])\n",
        "sigma_func = lambda i, j: 1.0  # Dummy sigma function\n",
        "\n",
        "svm = SVM()\n",
        "svm.fit(X, y, sigma_func)\n",
        "predictions = svm.predict(X, sigma_func)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uI6t8j_gvddy",
        "outputId": "68b9828d-3d8b-4c61-f8b9-5accea952c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Posterior mean estimates\n",
            "mu: 0.0\n",
            "phi: 0.9000000000000002\n",
            "sigma_eta: 0.10000000000000002\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class EKF:\n",
        "    def __init__(self, F, H, Q, R):\n",
        "        self.F = F\n",
        "        self.H = H\n",
        "        self.Q = Q\n",
        "        self.R = R\n",
        "\n",
        "    def predict(self, x, P):\n",
        "        x_pred = self.F @ x\n",
        "        P_pred = self.F @ P @ self.F.T + self.Q\n",
        "        return x_pred, P_pred\n",
        "\n",
        "    def update(self, x_pred, P_pred, y):\n",
        "        y_pred = self.H @ x_pred\n",
        "        S = self.H @ P_pred @ self.H.T + self.R\n",
        "        K = P_pred @ self.H.T @ np.linalg.inv(S)\n",
        "        x_upd = x_pred + K @ (y - y_pred)\n",
        "        P_upd = P_pred - K @ self.H @ P_pred\n",
        "        return x_upd, P_upd\n",
        "\n",
        "    def run(self, y, x0, P0):\n",
        "        n = len(y)\n",
        "        x_est = np.zeros((n, len(x0)))\n",
        "        x_est[0] = x0\n",
        "        P = P0\n",
        "        for t in range(1, n):\n",
        "            x_pred, P_pred = self.predict(x_est[t-1], P)\n",
        "            x_est[t], P = self.update(x_pred, P_pred, y[t])\n",
        "        return x_est\n",
        "\n",
        "class BayesianStochasticVolatilityEKF_HMC:\n",
        "    def __init__(self, F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.ekf = EKF(F, H, Q, R)\n",
        "        self.mu_prior = mu_prior\n",
        "        self.phi_prior = phi_prior\n",
        "        self.sigma_eta_prior = sigma_eta_prior\n",
        "        self.n_iter = n_iter\n",
        "        self.epsilon = epsilon  # Step size\n",
        "        self.L = L  # Number of leapfrog steps\n",
        "\n",
        "    def potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = sigma_eta if np.isscalar(sigma_eta) else sigma_eta.item()  # Ensure sigma_eta is a scalar\n",
        "        if sigma_eta <= 0:\n",
        "            return np.inf\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta**2]])\n",
        "        R = np.array([[1]])  # Assume observation noise is 1 for simplicity\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta**2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        likelihood = -0.5 * np.sum((y - x_est.flatten()) ** 2)\n",
        "        prior = -0.5 * (mu - self.mu_prior[0]) ** 2 / self.mu_prior[1] ** 2 \\\n",
        "                -0.5 * (phi - self.phi_prior[0]) ** 2 / self.phi_prior[1] ** 2 \\\n",
        "                -0.5 * (sigma_eta - self.sigma_eta_prior[0]) ** 2 / self.sigma_eta_prior[1] ** 2\n",
        "        return -(likelihood + prior)\n",
        "\n",
        "    def gradient_potential_energy(self, params, y):\n",
        "        mu, phi, sigma_eta = params\n",
        "        sigma_eta = np.atleast_1d(sigma_eta)[0]  # Convert sigma_eta to a scalar\n",
        "\n",
        "        F = np.array([[phi]])\n",
        "        H = np.array([[1]])\n",
        "        Q = np.array([[sigma_eta**2]])\n",
        "        R = np.array([[1]])\n",
        "\n",
        "        x0 = np.array([mu])\n",
        "        P0 = np.array([[sigma_eta**2]])\n",
        "\n",
        "        x_est = self.ekf.run(y, x0, P0)\n",
        "\n",
        "        grad_mu = 0\n",
        "        grad_phi = 0\n",
        "        grad_sigma_eta = 0\n",
        "        for t in range(1, len(y)):\n",
        "            grad_mu += (y[t] - x_est[t]) / np.exp(x_est[t])\n",
        "            grad_phi += (y[t] - x_est[t]) * (x_est[t-1] - mu) / np.exp(x_est[t])\n",
        "            grad_sigma_eta += (y[t] - mu - phi * y[t-1])**2 / (2 * sigma_eta**3)\n",
        "\n",
        "        grad_mu -= (mu - self.mu_prior[0]) / self.mu_prior[1] ** 2\n",
        "        grad_phi -= (phi - self.phi_prior[0]) / self.phi_prior[1] ** 2\n",
        "        grad_sigma_eta -= (sigma_eta - self.sigma_eta_prior[0]) / self.sigma_eta_prior[1] ** 2\n",
        "\n",
        "        return np.array([grad_mu.item(), grad_phi.item(), grad_sigma_eta.item()])\n",
        "\n",
        "    def leapfrog(self, params, momentum, grad, epsilon):\n",
        "        momentum_half_step = momentum - 0.5 * epsilon * grad\n",
        "        params_full_step = params + epsilon * momentum_half_step\n",
        "        grad_new = self.gradient_potential_energy(params_full_step, log_returns)\n",
        "        momentum_full_step = momentum_half_step - 0.5 * epsilon * grad_new\n",
        "        return params_full_step, momentum_full_step, grad_new\n",
        "\n",
        "    def hmc_step(self, params, y):\n",
        "        momentum = np.random.normal(size=params.shape)\n",
        "        current_params = params.copy()\n",
        "        current_momentum = momentum.copy()\n",
        "        current_grad = self.gradient_potential_energy(params, y)\n",
        "        proposed_params = params.copy()\n",
        "        proposed_momentum = momentum.copy()\n",
        "\n",
        "        for _ in range(self.L):\n",
        "            proposed_params, proposed_momentum, current_grad = self.leapfrog(proposed_params, proposed_momentum, current_grad, self.epsilon)\n",
        "\n",
        "        current_potential = self.potential_energy(current_params, y)\n",
        "        current_kinetic = 0.5 * np.sum(current_momentum ** 2)\n",
        "        proposed_potential = self.potential_energy(proposed_params, y)\n",
        "        proposed_kinetic = 0.5 * np.sum(proposed_momentum ** 2)\n",
        "\n",
        "        if np.random.uniform() < np.exp(current_potential - proposed_potential + current_kinetic - proposed_kinetic):\n",
        "            return proposed_params\n",
        "        else:\n",
        "            return current_params\n",
        "\n",
        "    def fit(self, y):\n",
        "        params = np.array([self.mu_prior[0], self.phi_prior[0], self.sigma_eta_prior[0]])\n",
        "        samples = np.zeros((self.n_iter, 3))\n",
        "        for i in range(self.n_iter):\n",
        "            params = self.hmc_step(params, y)\n",
        "            samples[i] = params\n",
        "        return samples\n",
        "\n",
        "# Example usage\n",
        "log_returns = np.random.normal(0, 0.1, 100)\n",
        "F = np.array([[0.9]])  # Initial transition matrix\n",
        "H = np.array([[1]])    # Observation matrix\n",
        "Q = np.array([[0.01]]) # Process noise covariance\n",
        "R = np.array([[1]])    # Observation noise covariance\n",
        "\n",
        "hmc_ekf_model = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior=(0, 1), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10)\n",
        "samples = hmc_ekf_model.fit(log_returns)\n",
        "\n",
        "print(\"Posterior mean estimates\")\n",
        "print(\"mu:\", np.mean(samples[:, 0]))\n",
        "print(\"phi:\", np.mean(samples[:, 1]))\n",
        "print(\"sigma_eta:\", np.mean(samples[:, 2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DS1mWL6Dlot4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823bd8b0-9fd9-42f6-a139-447fb2b92d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  1.  1. -1. -1.]\n",
            "[-1.  1.  1. -1.  1.]\n"
          ]
        }
      ],
      "source": [
        "class HybridModel:\n",
        "    def __init__(self, C=1.0, mu_prior=(0.0, 1.0), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.svm = SVM(C)\n",
        "        F = np.array([[phi_prior[0]]])  # Transition matrix\n",
        "        H = np.array([[1]])             # Observation matrix\n",
        "        Q = np.array([[sigma_eta_prior[0]**2]])  # Process noise covariance\n",
        "        R = np.array([[1]])             # Observation noise covariance\n",
        "        self.bsv = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter, epsilon, L)\n",
        "\n",
        "    def fit(self, X, y, log_returns):\n",
        "        samples = self.bsv.fit(log_returns)\n",
        "        h = np.mean(samples, axis=0)  # Use mean of samples for h\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))  # Simplified sigma function\n",
        "        self.svm.fit(X, y, sigma_func)\n",
        "\n",
        "    def predict(self, X):\n",
        "        samples = self.bsv.fit(np.zeros(len(X)))  # Dummy h values for prediction\n",
        "        h = np.mean(samples, axis=0)  # Use mean of samples for h\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))  # Simplified sigma function\n",
        "        return self.svm.predict(X, sigma_func)\n",
        "\n",
        "# Example usage\n",
        "log_returns = np.random.normal(0, 0.1, 100)\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]])\n",
        "y = np.array([1, 1, 1, -1, -1])\n",
        "\n",
        "hybrid_model = HybridModel()\n",
        "hybrid_model.fit(X, y, log_returns)\n",
        "hybrid_predictions = hybrid_model.predict(X)\n",
        "print(hybrid_predictions)\n",
        "class HybridModel:\n",
        "    def __init__(self, C=1.0, mu_prior=(0.0, 1.0), phi_prior=(0.9, 0.1), sigma_eta_prior=(0.1, 0.01), n_iter=1000, epsilon=0.01, L=10):\n",
        "        self.svm = SVM(C)\n",
        "        F = np.array([[phi_prior[0]]])  # Transition matrix\n",
        "        H = np.array([[1]])             # Observation matrix\n",
        "        Q = np.array([[sigma_eta_prior[0]**2]])  # Process noise covariance\n",
        "        R = np.array([[1]])             # Observation noise covariance\n",
        "        self.bsv = BayesianStochasticVolatilityEKF_HMC(F, H, Q, R, mu_prior, phi_prior, sigma_eta_prior, n_iter, epsilon, L)\n",
        "\n",
        "    def fit(self, X, y, log_returns):\n",
        "        samples = self.bsv.fit(log_returns)\n",
        "        h = np.mean(samples, axis=0)  # Use mean of samples for h\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))  # Simplified sigma function\n",
        "        self.svm.fit(X, y, sigma_func)\n",
        "\n",
        "    def predict(self, X):\n",
        "        samples = self.bsv.fit(np.zeros(len(X)))  # Dummy h values for prediction\n",
        "        h = np.mean(samples, axis=0)  # Use mean of samples for h\n",
        "        sigma_func = lambda i, j: np.sqrt(np.exp(h[0] + h[1]))  # Simplified sigma function\n",
        "        return self.svm.predict(X, sigma_func)\n",
        "\n",
        "# Example usage\n",
        "log_returns = np.random.normal(0, 0.1, 100)\n",
        "X = np.array([[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]])\n",
        "y = np.array([1, 1, 1, -1, -1])\n",
        "\n",
        "hybrid_model = HybridModel()\n",
        "hybrid_model.fit(X, y, log_returns)\n",
        "hybrid_predictions = hybrid_model.predict(X)\n",
        "print(hybrid_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPeGl-Vilz7c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc2bA05ssLx1d1d0ohqgnM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}